# DTI5125_Assignment2
# üìä Clustering Scientific Abstracts Using Sentence Embeddings and Unsupervised Learning
 
## üîç Project Overview
 
This project explores **unsupervised clustering** of scientific abstracts using **sentence embeddings** and a variety of **clustering techniques** including GMM, KMeans, HDBSCAN, and EVoC.
 
The goal is to group AI-related abstracts into meaningful clusters that correspond to five target categories, without using supervision during training.  
It is a **group assignment** for the course **DTI/GNG 5125 at the University of Ottawa**.
 
---
 
## üìÅ Repository Structure
 
| File/Folder                        | Description                                                  |
|-----------------------------------|--------------------------------------------------------------|
| `Data/`                           | Raw query files and the processed dataset for clustering     |
| `data_preparation.ipynb`          | Preprocesses and partitions abstracts from raw queries       |
| `PCA_GMM.ipynb`                   | Embeddings ‚Üí PCA ‚Üí GMM clustering ‚Üí Evaluation               |
| `TSNE_K-means.ipynb`              | Embeddings ‚Üí t-SNE ‚Üí KMeans clustering ‚Üí Evaluation          |
| `embeddings_UMAP_HDBSCAN.ipynb`   | Embeddings ‚Üí UMAP ‚Üí HDBSCAN ‚Üí Evaluation                     |
| `embeddings_EVoC.ipynb`           | Embeddings ‚Üí EVoC ‚Üí Topic modeling ‚Üí Visualization           |
| `main.py`                         | Entry-point script (currently prints a welcome message)      |
| `*.html`                          | Interactive 3D visualizations of clustering results           |
| `pyproject.toml`, `uv.lock`       | Dependency and environment management files                  |
| `README.md`                       | This project overview document                               |
 
---
 
## üìö Data Description
 
- **Source**: Abstracts collected from Web of Science across five AI application domains:
  - AI and Supply Chain Management
  - AI and Finance
  - AI and Marketing
  - AI and Economics
  - AI and Accounting
 
- **Preprocessing Steps**:
  - Encoding harmonization across CSVs
  - Stopword removal and tokenization using NLTK
  - Abstracts partitioned into 150-word chunks
  - Domain labels (`Target`) assigned for evaluation purposes
 
---
 
## üß† Clustering Techniques Used
 
The following clustering techniques were applied to sentence embeddings generated by `jinaai/jina-embeddings-v3`:
 
- **Gaussian Mixture Model (GMM)** with PCA
- **KMeans** with t-SNE and direct embeddings
- **HDBSCAN** with UMAP for dense clustering
- **EVoC** (Enhanced Variation of Clustering) with UMAP + BERTopic for cluster labeling
 
---
 
## üìä Results Summary
 
### üìå Evaluation Method:
- **Cohen‚Äôs Kappa Score** measures agreement between predicted clusters and actual labels
- Cluster labels aligned with true targets using the **Hungarian Algorithm**
- **BERTopic** applied in EVoC and GMM for interpretable cluster labels
 
### üèÅ Cohen's Kappa Scores:
| Method                         | Description                                  | Cohen's Kappa |
|-------------------------------|----------------------------------------------|----------------|
| **GMM on Raw Embeddings**     | Sentence embeddings directly clustered       | ~0.69‚Äì0.70     |
| **GMM with PCA (50D ‚Üí 2D)**   | PCA-reduced features fed to GMM              | ~0.66‚Äì0.68     |
| **KMeans on Embeddings**      | Raw sentence embeddings                      | ~0.65          |
| **KMeans with t-SNE**         | 2D t-SNE embeddings ‚Üí KMeans                 | ~0.67          |
| **HDBSCAN with UMAP**         | Dense regions clustered; noise filtered      | ~0.64 (with noise excluded) |
| **EVoC with UMAP + BERTopic** | Best interpretability and labeling potential | ~0.70+         |
 
### üîç Key Observations:
- **EVoC** performed best both visually and in evaluation, with **well-separated clusters** and meaningful **BERTopic-derived labels**.
- **GMM** worked effectively with PCA-reduced data and allowed generation of multiple visualizations (2D and 3D).
- **KMeans** showed decent performance, especially with t-SNE embeddings.
- **HDBSCAN** required tuning for cluster granularity but highlighted outliers (noise points) clearly.
 
---
 
## üìà Visualizations
 
Interactive 3D plots were generated using **Plotly** and **PyVista**:
 
| Output File                     | Description                        |
|--------------------------------|------------------------------------|
| `gmm_pca3d_clusters.html`      | GMM clusters on 3D PCA embeddings  |
| `kmeans_plotly.html`           | KMeans on 3D t-SNE embeddings      |
| `tsne_kmeans_plotly.html`      | KMeans on t-SNE (alternative plot) |
| `umap_hdbscan_plotly.html`     | HDBSCAN clusters in UMAP space     |
| `evoc_clusters_plot.html`      | EVoC clusters with BERTopic labels |
 
All HTML files are saved locally and can be opened in a web browser for exploration.
 
---
 
## üöÄ How to Run
 
### 1. Clone the Repository
 
```bash
git clone https://github.com/EtienneDNL/DTI5125_Assignment2.git
cd DTI5125_Assignment2
2. Set Up Environment
If using uv:
 
bash
Copy
Edit
uv venv .venv
source .venv/bin/activate
uv pip install -r pyproject.toml
Alternatively, use pip:
 
bash
Copy
Edit
pip install -r requirements.txt  # If generated manually
3. Prepare the Data
Run the notebook below to clean and prepare the abstract dataset:
 
bash
Copy
Edit
jupyter notebook data_preparation.ipynb
4. Run Analysis Pipelines
Choose one or more notebooks depending on the method you'd like to analyze:
 
bash
Copy
Edit
jupyter notebook PCA_GMM.ipynb
jupyter notebook TSNE_K-means.ipynb
jupyter notebook embeddings_UMAP_HDBSCAN.ipynb
jupyter notebook embeddings_EVoC.ipynb
5. View Results
Open the .html files in a browser to explore interactive 3D cluster visualizations.
 
üí° Insights
The choice of embedding and dimensionality reduction greatly impacts cluster quality.
 
EVoC and GMM both yield high-quality clusters with good alignment to the actual domains.
 
Topic modeling adds interpretability by labeling clusters with meaningful words.
 
Unsupervised clustering, when paired with proper embeddings, can approximate labeled classification performance.
 
üõ† Dependencies
Python 3.10+
 
sentence-transformers
 
scikit-learn
 
umap-learn
 
hdbscan
 
bertopic
 
plotly
 
pyvista
 
nltk
 
pandas, numpy, matplotlib
 
Install via uv, pip, or conda depending on your preference.
